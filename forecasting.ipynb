{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisite\n",
    "The data source used is the <strong style=\"color: green\">green</strong> taxi data for February 2016 from the following website: https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page (the files are stored in Parquet format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data source\n",
    "!mkdir data\n",
    "!wget -P ./data/ https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2016-02.parquet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start of the Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically reload imported packages\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import all the necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import adfuller # test for stationarity\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import pytz\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from itertools import product # cartesian product for gridsearch\n",
    "\n",
    "# import libraries that I created that may be useful in the future (who knows)\n",
    "from forecasting.plotting import datetime_line_plot, count_comparison_bar_plot, comparison_line_plot\n",
    "\n",
    "# other setup\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import warnings\n",
    "\n",
    "#allow multiple notebook displays without printing or `display`\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "#view all the columns when displayed in a notebook\n",
    "pd.set_option('display.max_columns', None)\n",
    "#set matplotlib default style\n",
    "plt.style.use('ggplot')\n",
    "warnings.filterwarnings(\"ignore\") # not recommended but for this assessment only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "trip_data = pd.read_parquet('./data/green_tripdata_2016-02.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Report the number of rows and columns of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows, num_columns = trip_data.shape\n",
    "print(f\"Number of rows: {num_rows}, Number of columns: {num_columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In any machine learning or statistical modelling, the most important phase (at least for me) is the data exploration. In this phase, the understanding of the data should be established and documents related to the data should be provided (like data dictionary).\n",
    "\n",
    "Even if the objective of the forecasting modelling is the to forecast the number of trips per hour. Having an access to a data dictionary is important.\n",
    "\n",
    "I've tried to look at the data dictionary of the taxi data and found the following table:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Field Name| Description|\n",
    "|----------|------------|\n",
    "|VendorID | A code indicating the LPEP provider that provided the record. <br> 1= Creative Mobile Technologies, LLC; <br> 2= VeriFone Inc.|\n",
    "lpep_pickup_datetime | The date and time when the meter was engaged.|\n",
    "lpep_dropoff_datetime | The date and time when the meter was disengaged.|\n",
    "Passenger_count | The number of passengers in the vehicle. This is a driver-entered value.|\n",
    "Trip_distance | The elapsed Trip Distance in Miles reported by the taximeter.|\n",
    "PULocationID | TLC Taxi Zone in which the taximeter was engaged|\n",
    "DOLocationID | TLC Taxi Zone in which the taximeter was disengaged|\n",
    "RateCodeID | The final rate code in effect at the end of the trip. <br> 1= Standard rate <br> 2=JFK <br> 3=Newark <br> 4=Nassau or Westchester <br> 5=Negotiated fare <br> 6=Group ride\n",
    "Store_and_fwd_flag | This flag indicates whether the trip record was held in vehicle memory before sending to the vendor, aka “store and forward,” because the vehicle did not have a connection to the server. <br> Y= store and forward trip <br> N= not a store and forward trip|\n",
    "Payment_type | A numeric code signifying how the passenger paid for the trip. <br> 1= Credit card <br> 2= Cash <br>3= No charge <br>4= Dispute <br>5= Unknown<br> 6= Voided trip |\n",
    "Fare_amount | The time-and-distance fare calculated by the meter.|\n",
    "Extra | Miscellaneous extras and surcharges. Currently, this only includes the $0.50 and $1 rush hour and overnight charges.|\n",
    "MTA_tax | $0.50 MTA tax that is automatically triggered based on the metered rate in use.|\n",
    "Improvement_surcharge | $0.30 improvement surcharge assessed on hailed trips at the flag drop. The improvement surcharge began being levied in 2015. |\n",
    "Tip_amount | This field is automatically populated for credit card tips. Cash tips are not included.\n",
    "Tolls_amount | Total amount of all tolls paid in trip. |\n",
    "Total_amount | The total amount charged to passengers. Does not include cash tips. |\n",
    "Trip_type | A code indicating whether the trip was a street-hail or a dispatch that is automatically assigned based on the metered rate in use but can be altered by the driver. <br>1= Street-hail <br>2= Dispatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few important points to note:\n",
    "1. The distance is measured in miles. It might be easier to convert this to kilometers, as it's a metric unit and could provide a more intuitively precise measurement.\n",
    "2. There's no timezone specified in the data dictionary, but since this data is from NYC, I can assume the timezone is EST/US Time.\n",
    "\n",
    "Converting these two columns to their respective units/data types will help us draw more accurate insights from our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two columns do not contain any data, and the trip_type has missing two data points.\n",
    "\n",
    "<u>Normally, I am deleting the columns that do not contain any data. In ACSS(my current employer), we always make sure that this is well communicated to the clients, to let them be aware and for them to check if there are any errors in the data collection.</u>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To have an easier time dealing with time-series data, I always use DateTimeIndex\n",
    "trip_data = trip_data.set_index('lpep_pickup_datetime') # can also use inplace=True\n",
    "trip_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making sure as well that we are in eastern timezone because the data is from NYC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_data.index = trip_data.index.tz_localize(pytz.utc).tz_convert('US/Eastern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the dtype\n",
    "trip_data.index.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting miles to kilometers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_constant = 1.609344 # 1 mile  = 1.609344km\n",
    "\n",
    "trip_data['trip_distance_km'] = trip_data['trip_distance'] * km_constant\n",
    "trip_data[['trip_distance_km', 'trip_distance']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*<p style=\"font-size:11px; color:orange\">For a non forecasting models, after reviewing the data dictionary, and consulting some concerns with the client, I always perform the univariate, bivariate, and multivariate analysis to the variables of interest.</p>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code has been stored in the folder ./forecasting/plotting.py\n",
    "datetime_line_plot(trip_data,\n",
    "                   'trip_distance_km',\n",
    "                   plot_title_name = 'Trip Distance (KM) by Time of Day', \n",
    "                   plot_xlabel_name= 'Date and Time', \n",
    "                   plot_ylabel_name= 'Trip Distance in Kilometers')\n",
    "print(\"Figure 1: Trip Distance (KM) by Time of Day\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without downsampling the data (averaging the trip distance per hour), we can see outliers in the first week of February. There are also longer trips in the middle of the month, which could mean that people tend to have longer trips on salary day/pay day (Assuming the payday are every 15th and 30th of the month), as stated in the NYC labor law: https://dol.ny.gov/frequency-pay, which mandates that clerical and other workers are paid at least twice per month."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the average hourly trip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_line_plot(trip_data,\n",
    "                   'trip_distance_km',\n",
    "                   freq='h',\n",
    "                   plot_title_name = 'Average Hourly Trip Distance (KM) by Time of Day', \n",
    "                   plot_xlabel_name= 'Date and Time', \n",
    "                   plot_ylabel_name= 'Trip Distance in Kilometers')\n",
    "print(\"Figure 2: Average Hourly Trip Distance (KM) by Time of Day\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that our trip is somehow stationary, which is what we need to consider when forecasting using ARIMA models. (But this will not be modeled, since the number of trips will be forecasted not the Hourly Distance)\n",
    "\n",
    "The created `datatime_line_plot` function has a `make_interactive` parameter to look at the line plot in more detailed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_line_plot(trip_data,\n",
    "                   'trip_distance_km',\n",
    "                   freq='h',\n",
    "                   plot_title_name = 'Average Hourly Trip Distance (KM) by Time of Day', \n",
    "                   plot_xlabel_name= 'Date and Time', \n",
    "                   plot_ylabel_name= 'Trip Distance in Kilometers',\n",
    "                   make_interactive=True)\n",
    "print(\"Figure 3: Average Hourly Trip Distance (KM) by Time of Day Interactive Plot\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following assumptions formulated are: \n",
    "\n",
    "1. Many people may be taking taxis for longer late night trips, could indicate that many people are using taxis for weekend getaways or business trips during the week to go to airport from their homes.\n",
    "2. There are shorter daytime trips, this suggests that taxis are often used for commuting to work, likely for people who live relatively close to their workplaces.\n",
    "3. This may reflect that people tend to stay closer to home, spending time with family rather than traveling long distances (or visit a friend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Popular pickup locations on weekdays vs weekends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract first the day of week first\n",
    "trip_data['day_of_week'] = trip_data.index.day_name()\n",
    "trip_data['day_of_week'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEEK_ENDS = ['Saturday', 'Sunday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the week days and the week ends\n",
    "week_ends_mask = trip_data['day_of_week'].isin(WEEK_ENDS)\n",
    "week_end_trips_data = trip_data[week_ends_mask].copy()\n",
    "week_day_trips_data = trip_data[~week_ends_mask].copy()\n",
    "\n",
    "# to check the filtered week end and week day\n",
    "week_end_trips_data['day_of_week'].unique()\n",
    "week_day_trips_data['day_of_week'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_comparison_bar_plot(week_day_trips_data, week_end_trips_data,\n",
    "                          column_name='PULocationID', df1_name='Weekdays', df2_name='Weekends', \n",
    "                          plot_title_name = 'Pickup Locations Count: Weekdays vs Weekends',\n",
    "                          plot_xlabel_name = \"Rank Number\",\n",
    "                          plot_ylabel_name = 'Trip Count')\n",
    "print(\"Figure 4: Pickup Locations Count: Weekdays vs Weekends\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plot shows the top 10 most frequent pick up locations. The top 1 is the location ID 75 on weekdays, and location ID 41 for week ends. \n",
    "However, the difference between the number of counts of weekdays and weekends is large, this is because weekday has 5 days, and weekend has 2. \n",
    "To solve this, we can compute the ratio, then rank the location ID. I can achieve this by adding a paramter `make_ratio = True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_comparison_bar_plot(week_day_trips_data, week_end_trips_data,\n",
    "                          make_ratio=True,\n",
    "                          column_name='PULocationID', df1_name='Weekdays', df2_name='Weekends', \n",
    "                          plot_title_name = 'Pickup Locations Proportion: Weekdays vs Weekends',\n",
    "                          plot_xlabel_name = \"Rank Number\",\n",
    "                          plot_ylabel_name = 'Trip Ratio')\n",
    "print(\"Figure 5: Pickup Locations Proportion: Weekdays vs Weekends\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we can say that the top 10 frequent location does not vary significantly and the ranking of the ratio is similar to the count.\n",
    "\n",
    "In conclusion, designating more taxis to location IDs 75, 41, 74, 7, 166, ..., and 97 on weekdays, and to location IDs 41, 255, 7, 74, 82, ..., and 97 on weekends, could optimize fleet utilization. The higher demand in these areas indicates that deploying more taxis there would likely capture a greater share of trips, leading to increased revenue. By aligning taxi ranking distribution with these demand patterns, the company can more effectively serve passengers and maximize earnings.\n",
    "\n",
    "The idea of fleet utilization has comes from here:\n",
    "- https://www.way.com/blog/fleet-use-meaning/\n",
    "- https://www.tourmo.ai/resources/learn/how-to-improve-fleet-utilization-in-3-steps-tm/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Build a model to forecast the number of trips per hour (ARIMA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this model, I will try to implement ARIMA model, and one requirement that we need to satify is the stationarity of the data.\n",
    "\n",
    "We have three ways to measure the stationarity of the data. These are the following:\n",
    "1. Visual inspection using time-series plot. If we see that we have constant mean and variance, and no seasonality, then we have stationary data. If the visual is hard to visualize, then we go to numbers 2 and 3 below.\n",
    "2. Using global tests. In this case, we measure the mean and std of the whole data, then we compute the mean of only a portion of data (For example: Jan to Feb, and the global mean is from Jan to Dec). If we have approimately similar mean and standard deviation, with no seasonality, then we can say that our data is stationary.\n",
    "3. Using augmented dickey-fuller test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook only shows 1 and 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_line_plot(trip_data,\n",
    "                   'trip_distance',\n",
    "                   freq='h',\n",
    "                   agg_operation='count',\n",
    "                   plot_title_name = 'Average Hourly Trip Count by Time of Day', \n",
    "                   plot_xlabel_name= 'Date and Time',\n",
    "                   plot_ylabel_name= 'Number of Trips',\n",
    "                   make_interactive=True)\n",
    "print(\"Figure 6: Average Hourly Trip Count by Time of Day\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 6 shows that the number of trips per hour peaks in the early evening / late afternoon, particularly between 16:00 and 17:00, which aligns with the end of typical working hours. In contrast, the lowest trip counts occur between 20:00 and 01:00, with fewer than a thousand trips during these hours. Based on Figure 3, which displays the average hourly trip distance by time of day, it appears that trips during these low-count hours tend to be longer. This may be due to business-related travel on weekdays or vacation trips on weekends, possibly including trips to the airport. \n",
    "\n",
    "Also, since there are peaks that are significantly larger than the other, I think this is non-stationary. To confirm this hypothesis, the augmented dickey-fuller test has been provided:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the hourly count\n",
    "hourly_count_trip_data = trip_data.resample('h').size()\n",
    "hourly_count_trip_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirming the initial assumption of non-stationarity, I calculate the augmented dickey-fuller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf_result = adfuller(hourly_count_trip_data)\n",
    "print(f\"Test Statistics = {adf_result[0]}\\nP-value = {adf_result[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The augmented dickey-fuller test above shows that our data is non-stationary, since we have higher p-value (In this case, I will use a 0.05 p-value to reject the null hypothesis). To make the data stationary, we can use differencing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_differencing(data, order=1):\n",
    "    \"\"\"\n",
    "        I think this can be done using recursion\n",
    "    \"\"\"\n",
    "    data = np.array(data)\n",
    "    differenced_data = [current_point - data[index-1] for index, current_point in enumerate(data) if index != 0]\n",
    "    \n",
    "    if order == 1:\n",
    "        return differenced_data\n",
    "    elif order > 1:\n",
    "        order=-1\n",
    "        return get_differencing(differenced_data, order=order)\n",
    "    else:\n",
    "        raise ValueError(\"Order is invalid\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I coded the above differencing, however, this can be easily achieved in pandas using `diff()` method. (adding two `diff()` methods would result to two levels  of differencing `diff().diff()`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffed_hourly_count_trip_data = hourly_count_trip_data.diff()\n",
    "diffed_hourly_count_trip_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the ADF again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf_result = adfuller(diffed_hourly_count_trip_data.fillna(method='bfill')) # I can dropna as well, it doesn't impact the result since it's only one observation\n",
    "print(f\"Test Statistics = {adf_result[0]}\\nP-value = {adf_result[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result now shows stationarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_line_plot(diffed_hourly_count_trip_data.to_frame().rename(columns={0: \"count\"}),\n",
    "                   \"count\",\n",
    "                   plot_title_name = 'Differenced Average Hourly Trip Count by Time of Day', \n",
    "                   plot_xlabel_name= 'Date and Time',\n",
    "                   plot_ylabel_name= 'Differenced Number of Trips',\n",
    "                   make_interactive=True)\n",
    "print(\"Figure 7. Differenced Average Hourly Trip Count by Time of Day\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above process shows how we convert the data to stationary, this is important since I can now specify that I only need one differencing to convert the data to stationary, which is useful in parameterizing the ARIMA model. Since I have now the first parameter, I can now look at the ACF and PACF plot for the Moving Average part and the Autoregressive part of the ARIMA model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ACF AND PACF Plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from statsmodels.api import graphics\n",
    "sm.graphics.tsa.plot_acf(diffed_hourly_count_trip_data.dropna())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the ACF plot, we can estimate the order for the moving average part. In this case, since the lags two does show a significant positive correlation and the next lag (lag 3) is not, we can set the moving average part order to 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.graphics.tsa.plot_pacf(diffed_hourly_count_trip_data.dropna())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the autoregressive part, I looked at the PACF, similar with the moving average part of the ARIMA model, I can set the order to 2.\n",
    "\n",
    "Finally, I can set the ARIMA order of (2, 1, 2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Looking at the trend, seasonality, and residual.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition = sm.tsa.seasonal_decompose(hourly_count_trip_data, model='additive')\n",
    "fig = decomposition.plot()\n",
    "plt.show()\n",
    "print(\"Figure 8. Observed, Trend, Seasonal, and Residual Plot of the Number of Hourly Trip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have observed that there's a seasonality, I think the model that we can use here is a Seasonal ARIMA. However, due to the time constraints, I cannot observe the seasonal order of the Seasonal ARIMA. However, since we only have February data, I think I can safely avoid using seasonality in this modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for the actual modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.tsa.arima.ARIMA(hourly_count_trip_data, order=(2,1,2))\n",
    "fitted_model = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_days = 12\n",
    "\n",
    "start_index = pd.to_datetime('2016-02-12 10:00:00', utc=True).tz_convert('US/Eastern')\n",
    "end_index = start_index + pd.DateOffset(days=num_days)\n",
    "print(f\"Forecast from {str(start_index)} to {end_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = fitted_model.get_prediction(start=start_index, end=end_index, dynamic=False)\n",
    "pred_ci = pred.conf_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groud_truth_hourly_trip = hourly_count_trip_data[start_index:end_index].to_frame().rename(columns={0: \"forecast\"})\n",
    "predicted_values = pred.predicted_mean.to_frame().rename(columns={\"predicted_mean\": \"forecast\"})\n",
    "comparison_line_plot(groud_truth_hourly_trip,\n",
    "                     predicted_values,\n",
    "                     column_name=\"forecast\",\n",
    "                     df1_name=\"True Values\",\n",
    "                     df2_name=\"Predicted Values\",\n",
    "                     plot_title_name = '12 Day Forecast: True Values vs Predicted Values', \n",
    "                     plot_xlabel_name= 'Date and Time',\n",
    "                     plot_ylabel_name= 'Forecast')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the prediction vs the true values. We see that model that I created can follow the trend of the data. Therefore, I think this is already a good (okay) model. However, I need to look at the plot_diagnostics and coefficients to see if the statistical assumptions have been met.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the summary although the predicted values are following the trend of the true values. Our statistical analysis says that our model is not good. The following are the reason:\n",
    "1. The ar.L1 and ar.L2 is the p parameter of our ARIMA model (the autoregressive part), since the P>|z| is not small, this could mean that the this lowly impacts the time-series model prediction. We need to think of a better way find the best value of the p (autoregressive part) parameter of the model or properly transform our data.\n",
    "2. The jarque bera p-value is low, which indicates we reject the idea that the residual is normally distributed. If we implement this model, we wouldn't get a valid confidence interval, coefficient estimates, and p-value.\n",
    "3. Ljung-Box (L1) is 0, which means that our residuals are not independent, which is also an important assumption.\n",
    "\n",
    "In this case, I think it is safe to asume that ARIMA cannot satify all the assumptions(the order that I inferred earlier may not be the optimal order). Other models, data transformations, and order should be considered as well. For now, I will evaluate the developed model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Evaluate your forecast model and outcomes using any measures you think are appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_model.plot_diagnostics(figsize=(15, 12))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "baseline = groud_truth_hourly_trip.mean()\n",
    "print(f'The baseline {round(baseline, 2)}')\n",
    "\n",
    "rmse = np.sqrt(((groud_truth_hourly_trip - predicted_values) ** 2).mean())\n",
    "print(f'The Mean Squared Error of our forecasts is {round(rmse, 2)}')\n",
    "\n",
    "mae = abs(groud_truth_hourly_trip - predicted_values).mean()\n",
    "print(f'The Mean Squared Error of our forecasts is {round(mae, 2)}')\n",
    "\n",
    "r2 = r2_score(groud_truth_hourly_trip, predicted_values)\n",
    "print(f'R Squared of our forecasts is {round(r2, 2)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although some statistical tests are not satisfied. The error of the prediction of the model is way lower than the baseline, which is the average count of the hourly trip, which is good. To support this, the R2 is also provided with 0.94, which means 94 of the variance of the variance can be explained by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Future improvements:\n",
    "1. Perform out-of-sample tests\n",
    "2. Try other models and other transformations to satisfy the statistical assumptions of the model.\n",
    "3. Find the most optimal order of ARIMA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizing the parameter using grid search\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\") # specify to ignore warning messages\n",
    "\n",
    "# p = range(0, 2)\n",
    "# d = range(1, 2)\n",
    "# q = range(0, 2)\n",
    "# for order in product(p, d, q):\n",
    "#     for seasonal_order in product(range(0, 5), range(0, 2), range(0, 5)):\n",
    "#         mod = sm.tsa.statespace.SARIMAX(hourly_count_trip_data,\n",
    "#                                 order=order,\n",
    "#                                 seasonal_order=(*seasonal_order, 12))\n",
    "#         result = mod.fit(disp=False)\n",
    "#         print(order, seasonal_order, 12)\n",
    "#         print(result.aic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
